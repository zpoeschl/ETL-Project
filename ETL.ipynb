{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from config import username, password"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diversity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_csv = \"Resources/diversityindex.csv\"\n",
    "diversity_df = pd.read_csv(diversity_csv)\n",
    "diversity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a a new df with info we need \n",
    "\n",
    "# Split the County coloum into State and County\n",
    "new_df = diversity_df\n",
    "new_df['County'], new_df['State'] = diversity_df['Location'].str.split(',').str\n",
    "new_df.tail()\n",
    "\n",
    "# Drops all rows that have NaN as County as States got split into County above. \n",
    "new_df = new_df.dropna()\n",
    "\n",
    "#checking if this worked and drop was sucessful in removing STATe names from county coloum \n",
    "\n",
    "# dsd = df[df['County'] == 'TEXAS']\n",
    "# dsd.tail()\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop uneccessary column \"Location\" - replaced by county, state columns\n",
    "diversity_df = new_df.drop(['Location'], axis=1)\n",
    "\n",
    "# rename columns for compatibility with SQL\n",
    "diversity_df = diversity_df.rename(columns={'Diversity-Index': 'diversity_index',\n",
    "                                            'Black or African American alone, percent, 2013': 'black',\n",
    "                                           'American Indian and Alaska Native alone, percent, 2013': 'native_am',\n",
    "                                           'Asian alone, percent, 2013': 'asian',\n",
    "                                           'Native Hawaiian and Other Pacific Islander alone, percent,': 'hawaiian',\n",
    "                                           'Two or More Races, percent, 2013': 'mixed',\n",
    "                                           'Hispanic or Latino, percent, 2013': 'latinx',\n",
    "                                           'White alone, not Hispanic or Latino, percent, 2013': 'white',\n",
    "                                           'County': 'county',\n",
    "                                           'State': 'state'})\n",
    "\n",
    "diversity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df2 = pd.DataFrame({\"Diversity-Index\":new_df.groupby([\"State\",\"County\"])[\"Diversity-Index\"].mean(),\n",
    "                       \"Black\":new_df.groupby([\"State\",\"County\"])[\"Black or African American alone, percent, 2013\"].mean(),\n",
    "                       \"American Indian\":new_df.groupby([\"State\",\"County\"])[\"American Indian and Alaska Native alone, percent, 2013\"].mean(),\n",
    "                       \"Asian\":new_df.groupby([\"State\",\"County\"])[\"Asian alone, percent, 2013\"].mean(),\n",
    "                       \"Native Hawaiian\":new_df.groupby([\"State\",\"County\"])[\"Native Hawaiian and Other Pacific Islander alone, percent,\"].mean(),\n",
    "                       \"Two or More Races\":new_df.groupby([\"State\",\"County\"])[\"Two or More Races, percent, 2013\"].mean(),\n",
    "                       \"Hispanic/ Latino\":new_df.groupby([\"State\",\"County\"])[\"Hispanic or Latino, percent, 2013\"].mean(),\n",
    "                       \"White\":new_df.groupby([\"State\",\"County\"])[\"White alone, not Hispanic or Latino, percent, 2013\"].mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unemployment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_csv = \"Resources/unemployment.csv\"\n",
    "unemp_df = pd.read_csv(unemp_csv)\n",
    "\n",
    "unemp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_df = unemp_df[['County', 'State', 'Rate']]\n",
    "unemp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_state_abbrev = {\n",
    "    \n",
    "'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA', 'Colorado': 'CO',\n",
    "'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA', 'Hawaii': 'HI', 'Idaho': 'ID',\n",
    "'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA', 'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA',\n",
    "'Maine': 'ME', 'Maryland': 'MD', 'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS',\n",
    "'Missouri': 'MO', 'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n",
    "'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH', 'Oklahoma': 'OK',\n",
    "'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC', 'South Dakota': 'SD',\n",
    "'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT', 'Virginia': 'VA', 'Washington': 'WA',\n",
    "'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_df['State'] = unemp_df['State'].map(us_state_abbrev).fillna(unemp_df['State'])\n",
    "\n",
    "# rename columns for compatibility with SQL\n",
    "unemp_df = unemp_df.rename(columns={'County': 'county', 'State': 'state', 'Rate': 'rate'})\n",
    "\n",
    "# drop duplicate rows\n",
    "unemp_df = unemp_df.drop_duplicates(subset=['county', 'state'])\n",
    "\n",
    "unemp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unemp_df_new = pd.DataFrame({\"Unemployment Rate\":unemp_df.groupby([\"State\",\"County\"])[\"Rate\"].mean()})\n",
    "# unemp_df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Income Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_csv = \"Resources/medianincome.csv\"\n",
    "median_df = pd.read_csv(median_csv)\n",
    "median_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_df = median_df[['County',\"State Code\", 'Population',\"Median household income\"]]\n",
    "\n",
    "# rename columns for compatibility with SQL\n",
    "median_df = median_df.rename(columns={'County': 'county', 'State Code': 'state', 'Population': 'population', 'Median household income': 'median_household_income'})\n",
    "\n",
    "median_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median_df = median_df.rename(columns={\"State Code\": \"State\"})\n",
    "\n",
    "\n",
    "# median_df_new = pd.DataFrame({\"Median household income\":median_df.groupby([\"State\",\"County\"])[\"Median household income\"].mean(),\n",
    "#                               \"Population\":median_df.groupby([\"State\",\"County\"])[\"Population\"].sum()})\n",
    "\n",
    "# median_df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "rds_connection_string = f\"{username}:{password}@localhost:5432/ETL_db\"\n",
    "engine = create_engine(f'postgresql://{rds_connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load converted dataframes into ETL_db\n",
    "median_df.to_sql(name='income', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_df.to_sql(name='diversity', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp_df.to_sql(name='unemployment', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
